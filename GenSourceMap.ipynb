{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Tools \n",
    "import pyfits, healpy\n",
    "reload(Tools)\n",
    "from scipy.integrate import quad \n",
    "from scipy.special import expn\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "\n",
    "def GetSpec(specType):\n",
    "    '''\n",
    "    Given a 2FGL Spectral type return lambdas for the spectrum and integrated spectrum\n",
    "    params:\n",
    "        specType: Can be 'PowerLaw','PLExpCutoff', or 'LogParabola' \n",
    "    returns: \n",
    "        Spec,IntegratedSpec: the spectrum and integrated spectrum.  See function def for param ordering. \n",
    "    '''\n",
    "    if specType == 'PowerLaw':\n",
    "        Spec           = lambda e,gamma: e**-gamma\n",
    "        IntegratedSpec = lambda e1,e2,gamma: (e1*e2)**-gamma * (e1*e2**gamma - e1**gamma*e2)/ (gamma-1)\n",
    "\n",
    "    elif specType == 'PLExpCutoff':\n",
    "        Spec           = lambda e,gamma,cutoff: e**-gamma * np.exp(-e/cutoff)\n",
    "        IntegratedSpec = lambda e1,e2,gamma,cutoff: e1**(1-gamma)*expn(gamma,e1/cutoff)-e2**(1-gamma)*expn(gamma,e2/cutoff)\n",
    "\n",
    "    elif specType== 'LogParabola':\n",
    "        Spec           = lambda e, alpha, beta, pivot: e**-(alpha+beta*np.log(e/pivot))\n",
    "        IntegratedSpec = lambda e1,e2,alpha,beta,pivot: quad(Spec,e1,e2,args=(alpha,beta,pivot))[0]\n",
    "    else:\n",
    "        raise Exception(\"Spectral type not supported.\")\n",
    "    \n",
    "    return Spec, IntegratedSpec\n",
    "    \n",
    "\n",
    "\n",
    "def GenSourceMap(bin_edges,l_range=[-180,180],b_range=[-45,45], \n",
    "                 fglpath='/data/gll_psc_v08.fit',\n",
    "                 expcube='/data/fermi_data_1-8-14/gtexpcube2_ALL_BOTH',\n",
    "                 psfFile='/data/fermi_data_1-8-14/psf_P7REP_SOURCE_BOTH.fits',\n",
    "                 maxPSF = 5.,\n",
    "                 res=0.125,\n",
    "                 nside=256,\n",
    "                 onlyidx=None):\n",
    "    '''\n",
    "    This method generates a source map based on an input catalog implementing the following procedure:\n",
    "    1. Integrate given spectrum to 2FGL over each energy bin to obtain counts/cm^2/s\n",
    "    2. Multiply  by effective exposure to obtain counts\n",
    "    3. Convolve with PSF to obtain the source map.\n",
    "    '''\n",
    "    # Load FGL cat\n",
    "    fgl_data = pyfits.open(fglpath)[1].data\n",
    "    # Init the master point source template\n",
    "    PSCMap = np.zeros(shape=(len(bin_edges)-1,12*nside**2))\n",
    "    \n",
    "    # Determine which sources are inside the spatial window. \n",
    "    idx_all = np.where(  (fgl_data['GLAT']<b_range[1]) & (fgl_data['GLAT']>b_range[0])\n",
    "                       & ( (fgl_data['GLON']<l_range[1]) | (fgl_data['GLON']>(l_range[0]+360)) ))[0]\n",
    "    \n",
    "    #idx_all = np.where(  (fgl_data['GLAT']<b_range[1]) & (fgl_data['GLAT']>b_range[0])\n",
    "    #                      & (fgl_data['GLON']>350))[0]\n",
    "    \n",
    "    \n",
    "    # Pre-load all the point spread functions as a function of fine energy binning so we can reweight against spectra.\n",
    "    hdu = pyfits.open(psfFile)\n",
    "    \n",
    "    thetas   = np.array([theta[0] for theta in hdu[2].data])\n",
    "    \n",
    "    energies = np.array([energy[0] for energy in hdu[1].data])\n",
    "    PSFs     = np.array([psf[2] for psf in hdu[1].data])\n",
    "    \n",
    "    # Iterate over sources \n",
    "    for i_idx, idx in enumerate(idx_all):\n",
    "        \n",
    "        # Debug\n",
    "        if onlyidx!=None:\n",
    "            if (i_idx not in onlyidx):continue\n",
    "        \n",
    "        #-----------------------------------------------------------\n",
    "        # First we determine the number of counts.\n",
    "        \n",
    "        # Retreive the spectrum and integrated spectrum functions\n",
    "        specType = fgl_data['SpectrumType'][idx]\n",
    "        spec, IntegratedSpec = GetSpec(specType)\n",
    "        \n",
    "        # Get the spectral parameters\n",
    "        specIndex = fgl_data['Spectral_Index'][idx]\n",
    "        beta      = fgl_data['beta'][idx]\n",
    "        fluxDens  = fgl_data['Flux_Density'][idx]\n",
    "        pivot     = fgl_data['Pivot_Energy'][idx]\n",
    "        cutoff    = fgl_data['Cutoff'][idx]\n",
    "        glat = fgl_data['GLAT'][idx]\n",
    "        glon = fgl_data['GLON'][idx]\n",
    "        \n",
    "        # Find the Normalization and integrate the spectrum over each energy bin\n",
    "        if specType == 'PowerLaw':\n",
    "            norm = fluxDens/spec(pivot,specIndex)\n",
    "            counts = norm*np.array([IntegratedSpec(bin_edges[i_E],bin_edges[i_E+1],specIndex) for i_E in range(len(bin_edges)-1)])            \n",
    "            psfWeights = spec(energies,specIndex)            \n",
    "            \n",
    "        elif specType == 'PLExpCutoff':\n",
    "            norm = fluxDens/spec(pivot,specIndex,cutoff)\n",
    "            counts = norm*np.array([IntegratedSpec(bin_edges[i_E],bin_edges[i_E+1],specIndex,cutoff) for i_E in range(len(bin_edges)-1)])                \n",
    "            psfWeights = spec(energies,specIndex,cutoff)\n",
    "        elif specType== 'LogParabola':\n",
    "            norm = fluxDens/spec(pivot,specIndex,beta,pivot)\n",
    "            counts = norm*np.array([IntegratedSpec(bin_edges[i_E],bin_edges[i_E+1],specIndex,beta,pivot) for i_E in range(len(bin_edges)-1)])\n",
    "            psfWeights = spec(energies,specIndex,beta,pivot)\n",
    "        \n",
    "        # Now counts contains ph/cm^2/s^2 for each bin so we need to get the effective area in each bin. \n",
    "        exposure = np.array([Tools.GetExpMap(bin_edges[i_E],bin_edges[i_E+1],glon,glat,expcube) for i_E in range(len(bin_edges)-1)]) \n",
    "        # Now the counts are in actual counts\n",
    "        counts = counts*exposure\n",
    "        \n",
    "        #-----------------------------------------------------------\n",
    "        # Apply PSF\n",
    "        avgPSF = [] \n",
    "        size = 2*maxPSF/res+1\n",
    "        lats, lons = np.linspace(-maxPSF,maxPSF,size), np.linspace(-maxPSF,maxPSF,size)\n",
    "        \n",
    "        \n",
    "        # Calculate the reweighted PSF in each energy bin for this source's spectrum.\n",
    "        for i_E in range(len(bin_edges)-1):\n",
    "            e1,e2 = bin_edges[i_E],bin_edges[i_E+1]\n",
    "            eb1, eb2 = np.argmin(np.abs(energies-e1)), np.argmin(np.abs(energies-e2))\n",
    "            avgPSF = np.average(PSFs[eb1:eb2],weights=psfWeights[eb1:eb2],axis=0)\n",
    "            avgPSFInterp = lambda r: np.interp(r,thetas,avgPSF)\n",
    "            \n",
    "            # Form a cartesian array for this PSF which will be mapped to the healpix grid\n",
    "            cartMap = np.zeros(shape=(size,size))\n",
    "            \n",
    "            # Scan over latitudes and fill in PSF value \n",
    "            for i_lat, lat in enumerate(lats):\n",
    "                # Now calculate distances for each point \n",
    "                r = np.sqrt(lat**2+lons**2)\n",
    "                cartMap[i_lat,:] = avgPSFInterp(r)# *res**2*(np.pi/180.)**2\n",
    "            \n",
    "            # Mult by solid angle/px and sum gives ~1. Good! \n",
    "            # We will just renormalize sum to 1 since there is a small error\n",
    "            cartMap = cartMap/cartMap.sum()*counts[i_E] # Now units are photons falling in that pixel. \n",
    "            \n",
    "            # Now we need to map this grid onto the healpix grid. \n",
    "            for i_lat, lat in enumerate(lats):\n",
    "                realLat = glat+lat \n",
    "                # If we crossed the pole, also flip the meridian. \n",
    "                # TODO FIX BEHAVIOR NEAR POLES Currently not handled correctly\n",
    "                # A GOOD WAY TO DO THIS WOULD BE TO USE THE GAMMACAP CODE WHICH \n",
    "                # ROTATES A GIVEN INITIAL POSITION UP TO A SKYMAP POSITION. \n",
    "                if realLat > 90.: realLat-=90.\n",
    "                if realLat < -90.: realLat+=90.\n",
    "                if glon>180: glon-=360.\n",
    "                # Take care of rescaling the effective longitude based on the latitude.\n",
    "                # longitude doesn't really matter if we are right a N/S pole.\n",
    "                #if np.abs(90-np.abs(realLat))>.125: new_lons = ((glon+lons)/np.cos(np.deg2rad(realLat)))%360\n",
    "                new_lons = (glon+lons/np.cos(np.deg2rad(realLat)))%360\n",
    "                # Find the which hpix bin each pixel falls and add the counts\n",
    "                hpix_idx = Tools.ang2hpix(new_lons,realLat,nside=nside)\n",
    "                # Add the values to the healpix grid.  Must use this 'at' method in order to\n",
    "                # correctly add repeated indices.\n",
    "                np.add.at(PSCMap[i_E],hpix_idx,cartMap[i_lat])\n",
    "            #print cartMap.sum()\n",
    "        \n",
    "        \n",
    "        if i_idx%1==0:\n",
    "            print '\\rFraction Complete:', '%.3f' % (np.float(i_idx)/len(idx_all)),\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    return PSCMap\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------\n",
    "    # Integrate the source spectrum \n",
    "    \n",
    "    \n",
    "bin_edges=[300, 350, 400, 450, 500, 557.4511962326, 624.9931144482831, 705.0811841511901, 800.9547380631948, 916.9544789959854, 1058.9994895010252, 1235.32183584898, 1457.6298200740125, 1743.0094229290717, 2117.148088832825, 2620.038055486477, 3316.5858204132596, 4317.5724796525965, 5824.226374320851, 8232.171915073328, 12404.648624640446, 20517.115667189668, 39361.808463774716, 99337.18520898951, 499999.9999999654]\n",
    "cmap = GenSourceMap(bin_edges,onlyidx=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import healpy\n",
    "#hdu=pyfits.open ('/data/fermi_data_1-8-14/gtexpcube2_ALL_BOTH')\n",
    "#print hdu[0].header.cards\n",
    "#print hdu[0].data.max()\n",
    "\n",
    "\n",
    "#healpy.mollview(np.log10())\n",
    "#healpy.mollview((np.log10(A.binned_data[10])))\n",
    "healpy.mollview(np.log10(cmap[10]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (2.44972e+11/800)/3.15e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Analysis\n",
    "reload(Analysis)\n",
    "A = Analysis.Analysis()\n",
    "A.BinPhotons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetSpec(specType):\n",
    "    if specType == 'PowerLaw':\n",
    "        Spec = lambda e,gamma: e**-gamma\n",
    "        IntegratedSpec = lambda e1,e2,gamma: (e1*e2)**-gamma * (e1*e2**gamma - e1**gamma*e2)/ (gamma-1)\n",
    "\n",
    "    if specType == 'PLExpCutoff':\n",
    "        Spec = lambda e,gamma,cutoff: e**-gamma * np.exp(-e/cutoff)\n",
    "        IntegratedSpec = lambda e1,e2,gamma,cutoff: e1**(1-gamma)*expn(gamma,e1/cutoff)-e2**(1-gamma)*expn(gamma,e2/cutoff)\n",
    "\n",
    "    if specType== 'LogParabola':\n",
    "        Spec = lambda e, alpha, beta, pivot: e**-(alpha+beta*np.log(e/pivot))\n",
    "        IntegratedSpec = lambda e1,e2,alpha,beta,pivot: quad(Spec,e1,e2,args=(alpha,beta,pivot))[0]\n",
    "    \n",
    "    return Spec, IntegratedSpec\n",
    "    \n",
    "\n",
    "spec, IntegratedSpec = GetSpec(specType='PowerLaw')\n",
    "print IntegratedSpec(100,1e5,2)\n",
    "\n",
    "spec, IntegratedSpec = GetSpec(specType='PLExpCutoff')\n",
    "print IntegratedSpec(100,1e5,2,1e3)\n",
    "    \n",
    "spec, IntegratedSpec = GetSpec(specType='LogParabola')\n",
    "print IntegratedSpec(100,1e5,2,1,1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyfits.open('bubble_templates_diskcut30.0.fits')[1].header.cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sqrt(3145770/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  },
  "signature": "sha256:9162ee469e48c1e4688dbe0d0d169dd0df302bddb01e02a46849bf94931c1ad9"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}